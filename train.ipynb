{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fufsob/vuz/tpr/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-05-12 12:49:57.271218: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-12 12:50:10.608060: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = pd.read_csv(\"dataset/data.csv\")\n",
    "size = raw_dataset[\"size\"][0]\n",
    "# path,kana,font,size,antialias\n",
    "labels_map = json.load(open(\"dataset/mapping.json\"))\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_image_label(path, label):\n",
    "    return load_image(path), label\n",
    "\n",
    "\n",
    "def load_label(label):\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (raw_dataset[\"path\"], raw_dataset[\"kana\"].map(load_label))\n",
    "    )\n",
    "    dataset = dataset.map(load_image_label)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            # grayscale images 24x24, labels len(labels_map)\n",
    "            keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(size, size, 1)),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(len(labels_map), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "dataset = create_dataset()\n",
    "\n",
    "# dataset = dataset.shuffle(len(raw_dataset), seed=42)\n",
    "images = np.array([image for image, label in dataset])\n",
    "labels = np.array([label for image, label in dataset])\n",
    "# train_size = int(len(raw_dataset) * 0.8)\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# train_images = np.array([image for image, label in train_dataset])\n",
    "# train_labels = np.array([label for image, label in train_dataset])\n",
    "# test_dataset = dataset.skip(train_size)\n",
    "# test_images = np.array([image for image, label in test_dataset])\n",
    "# test_labels = np.array([label for image, label in test_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95658, 64, 64, 1)\n",
      "[  0   1   2 ... 146 147 148]\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 52ms/step - accuracy: 0.6906 - loss: 1.3118 - val_accuracy: 0.8880 - val_loss: 0.4039\n",
      "Epoch 2/40\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 45ms/step - accuracy: 0.9663 - loss: 0.0885 - val_accuracy: 0.9150 - val_loss: 0.2983\n",
      "Epoch 3/40\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.9769 - loss: 0.0547 - val_accuracy: 0.9151 - val_loss: 0.3311\n",
      "Epoch 4/40\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 44ms/step - accuracy: 0.9792 - loss: 0.0464 - val_accuracy: 0.9231 - val_loss: 0.3163\n",
      "Epoch 5/40\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9830 - loss: 0.0384 - val_accuracy: 0.9216 - val_loss: 0.3579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1073c0d250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(420)\n",
    "output_dir = Path(\"output\")\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir, ignore_errors=True)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "model.fit(\n",
    "    images,\n",
    "    labels,\n",
    "    epochs=40,\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir='output/logs'),\n",
    "        keras.callbacks.ModelCheckpoint('output/model_{epoch}.weights.h5', save_weights_only=True),\n",
    "        keras.callbacks.ModelCheckpoint('output/model.keras', save_best_only=True),\n",
    "        keras.callbacks.EarlyStopping(\"val_loss\", patience=3),\n",
    "    ],\n",
    "    validation_freq=1,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2990/2990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.9735 - loss: 0.0642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09987399727106094, 0.9655961990356445]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: keras.models.Sequential = keras.models.load_model('output/model.keras')\n",
    "model.evaluate(images, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
